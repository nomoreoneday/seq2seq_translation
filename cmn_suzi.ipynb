{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Requirements\n#reference: https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n\nfrom __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\nimport jieba\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nimport torch.nn.functional as F\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SOS_token = 0\nEOS_token = 1","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 定义vocabulary类\n# 主要用于储存单词与id的映射\nclass Vocabulary(object):\n    def __init__(self):\n        self.word2idx = {}\n        self.idx2word = {0: \"<SOS>\", 1: \"<EOS>\", -1: \"<unk>\"}\n        self.idx = 2 # 当前长度（包括 SOS and EOS）\n        \n    # 记录word和id之间的映射\n    def add_word(self, word):\n        if not word in self.word2idx:\n            self.word2idx[word] = self.idx\n            self.idx2word[self.idx] = word\n            self.idx += 1\n            \n    # 将句子进行分词，添加每个单词与id的映射\n    def add_sentence_eng(self, sentence):\n        for word in sentence.split():\n            self.add_word(word)\n            \n    def add_sentence_chn(self, sentence):\n        for word in sentence:\n            self.add_word(word)\n            \n   # 得到某个单词的id\n    def __call__(self, word):\n        if not word in self.word2idx:\n            return -1\n        return self.word2idx[word]\n   # vaocabulary的容量\n    def __len__(self):\n        return self.idx\n","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Load the dataset**\nThe files are all in Unicode, to simplify we will turn Unicode characters to ASCII, make everything lowercase, and trim most punctuation."},{"metadata":{"trusted":true},"cell_type":"code","source":"def unicode_to_ascii(s):\n    return ''.join(c for c in unicodedata.normalize('NFD', s)\n                   if unicodedata.category(c) != 'Mn')\n\n\ndef preprocess_eng(w):\n    w = unicode_to_ascii(w.lower().strip())\n\n    # creating a space between a word and the punctuation following it\n    # eg: \"he is a boy.\" => \"he is a boy .\"\n    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\n    w = re.sub(r\"([?.!,])\", r\" \\1 \", w)\n    # replace several spaces with one space\n    w = re.sub(r'[\" \"]+', \" \", w)\n\n    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n    w = re.sub(r\"[^a-zA-Z?.!,]+\", \" \", w)\n    w = w.rstrip().strip()\n    return w\n\ndef preprocess_chinese(w):\n    w = unicode_to_ascii(w.lower().strip())\n    w = re.sub(r'[\" \"]+', \"\", w)\n    w = w.rstrip().strip()\n    w = jieba.lcut(w)\n    return w\n\n# 选取数据集中长度小于15的句子\nMAX_LENGTH = 15\n\neng_prefixes = (\n    \"i am \", \"i m \",\n    \"he is\", \"he s \",\n    \"she is\", \"she s \",\n    \"you are\", \"you re \",\n    \"we are\", \"we re \",\n    \"they are\", \"they re \"\n)\n\ndef filterPair(p):\n    return len(p[0].split(' ')) < 15 and \\\n        len(p[1]) < 15 and \\\n        p[0].startswith(eng_prefixes)\n\ndef filterPairs(pairs):\n    return [pair for pair in pairs if filterPair(pair)]\n\n# read the dataset, and return a list，each element is like [language1, language2]\ndef create_dataset(path, num_examples = None):\n    lines = open(path, encoding='UTF-8').read().strip().split('\\n')\n    word_pairs = [[w for w in l.split('\\t')] for l in lines[:num_examples]]\n    word_pairs = [[preprocess_eng(w[0]), preprocess_chinese(w[1])]\n                  for w in word_pairs]\n    word_pairs = filterPairs(word_pairs)\n\n    return word_pairs\n\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load the data\nword_pairs = create_dataset('../input/cmn.txt')\nprint(\"Read %s sentence pairs\" % len(word_pairs))\n\nprint(\"-------------------------------------\") \n#Show first 10 pairs\nprint(\"Show 10 examples\")\nfor i in range(10):\n    print(word_pairs[i])\n    \n#built Vocabulary for lan1 and lan2     \nEng = Vocabulary()\nChn = Vocabulary()\n\nfor i,j in word_pairs:\n    Eng.add_sentence_eng(i)\n    Chn.add_sentence_chn(j)\nprint(\"-------------------------------------\")        \nprint(\"number of English words %s\" % len(Eng))\nprint(\"number of Chinese words %s\" % len(Chn))\n","execution_count":5,"outputs":[{"output_type":"stream","text":"Building prefix dict from the default dictionary ...\nDumping model to file cache /tmp/jieba.cache\nLoading model cost 1.240 seconds.\nPrefix dict has been built successfully.\n","name":"stderr"},{"output_type":"stream","text":"Read 1652 sentence pairs\n-------------------------------------\nShow 10 examples\n['i m ok .', ['我', '沒事', '。']]\n['i m ill .', ['我', '生病', '了', '。']]\n['i m old .', ['我', '老', '了', '。']]\n['i m wet .', ['我', '濕', '了', '。']]\n['i m busy .', ['我', '很', '忙', '。']]\n['i m cold .', ['我', '冷', '。']]\n['i m fine .', ['我', '很', '好', '。']]\n['i m full .', ['我', '吃', '飽', '了', '。']]\n['i m lost .', ['我', '迷失', '了', '。']]\n['i m sick .', ['我', '生病', '了', '。']]\n-------------------------------------\nnumber of English words 1320\nnumber of Chinese words 1959\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### **Define EncoderENN**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class EncoderRNN(nn.Module):\n    def __init__(self, input_size, hidden_size):\n        super(EncoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        \n        #定义一个Embedding和一个GRU层\n        self.embedding = nn.Embedding(input_size, hidden_size)  # 转化为词向量\n        self.gru = nn.GRU(hidden_size, hidden_size)\n\n    def forward(self, input, hidden):\n        embedded = self.embedding(input).view(1, 1, -1)\n        output = embedded\n        output, hidden = self.gru(output, hidden)\n        return output, hidden\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)\n","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Define AttnDecoderRNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"#引入Attension机制\n\nclass AttnDecoderRNN(nn.Module):\n    def __init__(self, hidden_size, output_size, dropout_p=0.1,max_length = MAX_LENGTH):\n        super(AttnDecoderRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.output_size = output_size\n        self.dropout_p = dropout_p\n        self.max_length = max_length\n\n        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n        self.dropout = nn.Dropout(self.dropout_p)\n        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n        self.out = nn.Linear(self.hidden_size, self.output_size)\n\n    def forward(self, input, hidden, encoder_outputs):\n        embedded = self.embedding(input).view(1, 1, -1)\n        embedded = self.dropout(embedded)\n\n        attn_weights = F.softmax(\n            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n                                 encoder_outputs.unsqueeze(0))\n\n        output = torch.cat((embedded[0], attn_applied[0]), 1)\n        output = self.attn_combine(output).unsqueeze(0)\n\n        output = F.relu(output)\n        output, hidden = self.gru(output, hidden)\n\n        output = F.log_softmax(self.out(output[0]), dim=1)\n        return output, hidden, attn_weights\n\n    def initHidden(self):\n        return torch.zeros(1, 1, self.hidden_size, device=device)","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare the training dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"#处理句子，将句子转化成Tensor\ndef sentence2tensor_eng(lang,sentence):\n    indexes = [lang(word) for word in sentence.split()]\n    indexes.append(EOS_token)\n    return torch.tensor(indexes,dtype=torch.long,device = device).view(-1,1)\n\ndef sentence2tensor_chn(lang,sentence):\n    indexes = [lang(word) for word in sentence]\n    indexes.append(EOS_token)\n    return torch.tensor(indexes,dtype=torch.long,device = device).view(-1,1)\n\n# 将（input，target) 的pair都转化成Tensor\ndef pair2tensor(pair):\n    input_tensor = sentence2tensor_eng(Eng,pair[0])\n    target_tensor = sentence2tensor_chn(Chn,pair[1])\n    return (input_tensor,target_tensor)","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Traning the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"teacher_forcing_ratio = 0.5\n\ndef train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length = MAX_LENGTH):\n    #初始化\n    encoder_hidden = encoder.initHidden()\n    #tidu\n    encoder_optimizer.zero_grad()\n    decoder_optimizer.zero_grad()\n\n    input_length = input_tensor.size(0)\n    target_length = target_tensor.size(0)\n\n    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n    loss = 0\n\n    for ei in range(input_length):\n        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n        encoder_outputs[ei] = encoder_output[0, 0]\n        \n    # the <SOS> is taken as its first input\n    decoder_input = torch.tensor([[SOS_token]], device=device)\n\n    decoder_hidden = encoder_hidden\n\n    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n\n    if use_teacher_forcing:\n        # Teacher forcing: Feed the target as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n            loss += criterion(decoder_output, target_tensor[di])\n            decoder_input = target_tensor[di]  # Teacher forcing\n\n    else:\n        # Without teacher forcing: use its own predictions as the next input\n        for di in range(target_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            topv, topi = decoder_output.topk(1)\n            decoder_input = topi.squeeze().detach()  # detach from history as input\n\n            loss += criterion(decoder_output, target_tensor[di])\n            if decoder_input.item() == EOS_token:\n                break\n\n    loss.backward()\n\n    encoder_optimizer.step()\n    decoder_optimizer.step()\n\n    return loss.item() / target_length","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport math\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s / (percent)\n    rs = es - s\n    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n    start = time.time()\n    plot_losses = []\n    print_loss_total = 0  \n    plot_loss_total = 0 \n\n    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n    \n    training_pairs = [pair2tensor(random.choice(word_pairs)) for i in range(n_iters)]\n    criterion = nn.NLLLoss()\n\n    for iter in range(1, n_iters + 1):\n        training_pair = training_pairs[iter - 1]\n        input_tensor = training_pair[0]\n        target_tensor = training_pair[1]\n\n        loss = train(input_tensor, target_tensor, encoder,decoder, encoder_optimizer, decoder_optimizer, criterion)\n        print_loss_total += loss\n        plot_loss_total += loss\n\n        if iter % print_every == 0:\n            print_loss_avg = print_loss_total / print_every\n            print_loss_total = 0\n            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),iter, iter / n_iters * 100, print_loss_avg))\n\n        if iter % plot_every == 0:\n            plot_loss_avg = plot_loss_total / plot_every\n            plot_losses.append(plot_loss_avg)\n            plot_loss_total = 0\n\n    showPlot(plot_losses)","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n#plt.switch_backend('agg')\nimport matplotlib.ticker as ticker\nimport numpy as np\n\n\ndef showPlot(points):\n    plt.figure()\n    fig, ax = plt.subplots()\n    # this locator puts ticks at regular intervals\n    loc = ticker.MultipleLocator(base=0.2)\n    ax.yaxis.set_major_locator(loc)\n    plt.plot(points)\n    plt.savefig('loss_curve')","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n    with torch.no_grad():\n        input_tensor = sentence2tensor_eng(Eng, sentence)\n        input_length = input_tensor.size()[0]\n        encoder_hidden = encoder.initHidden()\n\n        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n\n        for ei in range(input_length):\n            encoder_output, encoder_hidden = encoder(input_tensor[ei],\n                                                     encoder_hidden)\n            encoder_outputs[ei] += encoder_output[0, 0]\n\n        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n\n        decoder_hidden = encoder_hidden\n\n        decoded_words = []\n        decoder_attentions = torch.zeros(max_length, max_length)\n\n        for di in range(max_length):\n            decoder_output, decoder_hidden, decoder_attention = decoder(\n                decoder_input, decoder_hidden, encoder_outputs)\n            decoder_attentions[di] = decoder_attention.data\n            topv, topi = decoder_output.data.topk(1)\n            if topi.item() == EOS_token:\n                decoded_words.append('<EOS>')\n                break\n            else:\n                decoded_words.append(Chn.idx2word[topi.item()])\n\n            decoder_input = topi.squeeze().detach()\n\n        return decoded_words, decoder_attentions[:di + 1]\n    ","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluateRandomly(encoder, decoder, n=10):\n    for i in range(n):\n        pair = random.choice(word_pairs)\n        print('>', pair[0])\n        print('=', pair[1])\n        output_words, attentions = evaluate(encoder, decoder, pair[0])\n        output_sentence = ' '.join(output_words)\n        print('<', output_sentence)\n        print('')","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hidden_size = 256\nencoder1 = EncoderRNN(Eng.idx, hidden_size).to(device)\nattn_decoder1 = AttnDecoderRNN(hidden_size, Chn.idx, dropout_p=0.1).to(device)\ntrainIters(encoder1, attn_decoder1, 60000, print_every=5000)","execution_count":null,"outputs":[{"output_type":"stream","text":"1m 39s (- 18m 19s) (5000 8%) 3.6167\n3m 18s (- 16m 30s) (10000 16%) 2.6634\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluateRandomly(encoder1, attn_decoder1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}